{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# def visualize(h, color):\n",
    "#     z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# print()\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('======================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "# print()\n",
    "# print(data)\n",
    "# print('===========================================================================================================')\n",
    "\n",
    "# # Gather some statistics about the graph.\n",
    "# print(f'Number of nodes: {data.num_nodes}')\n",
    "# print(f'Number of edges: {data.num_edges}')\n",
    "# print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "# print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "# print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "# print(f'Has self-loops: {data.has_self_loops()}')\n",
    "# print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piotrgzubicki/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:155: UserWarning: There exist node types ({'author'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behaviour.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 26\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39m# def forward(self, x, edge_index):\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m#     x = F.dropout(x, p=0.5, training=self.training)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m#     x = self.conv1(x, edge_index)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39m#     x = self.conv2(x, edge_index)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m#     return x\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model \u001b[39m=\u001b[39m GNN(hidden_channels\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, out_channels\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m---> 26\u001b[0m model \u001b[39m=\u001b[39m to_hetero(model, data\u001b[39m.\u001b[39;49mmetadata(), aggr\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:119\u001b[0m, in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mwhich node representations are learned for each node type in\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m        transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m transformer \u001b[39m=\u001b[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m transformer\u001b[39m.\u001b[39;49mtransform()\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/fx.py:157\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39melif\u001b[39;00m is_global_pooling_op(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, op, node\u001b[39m.\u001b[39mtarget):\n\u001b[1;32m    156\u001b[0m         op \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcall_global_pooling_module\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, op)(node, node\u001b[39m.\u001b[39;49mtarget, node\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m    159\u001b[0m \u001b[39m# Remove all unused nodes in the computation graph, i.e., all nodes\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m# which have been replaced by node type-wise or edge type-wise variants\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m# but which are still present in the computation graph.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m# We do this by iterating over the computation graph in reversed order,\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# and try to remove every node. This does only succeed in case there\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m# are no users of that node left in the computation graph.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mnodes)):\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:307\u001b[0m, in \u001b[0;36mToHeteroTransformer.call_method\u001b[0;34m(self, node, target, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minserting_after(node)\n\u001b[1;32m    306\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata[\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_edge_level(node))]:\n\u001b[0;32m--> 307\u001b[0m     args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap_args_kwargs(node, key)\n\u001b[1;32m    308\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mcreate_node(\u001b[39m'\u001b[39m\u001b[39mcall_method\u001b[39m\u001b[39m'\u001b[39m, target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m    309\u001b[0m                                  args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    310\u001b[0m                                  name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00mkey2str(key)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minserting_after(out)\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:410\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs\u001b[0;34m(self, node, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m         \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 410\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(_recurse(v) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m node\u001b[39m.\u001b[39;49margs)\n\u001b[1;32m    411\u001b[0m kwargs \u001b[39m=\u001b[39m {k: _recurse(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    412\u001b[0m \u001b[39mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:410\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m         \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 410\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(_recurse(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39margs)\n\u001b[1;32m    411\u001b[0m kwargs \u001b[39m=\u001b[39m {k: _recurse(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    412\u001b[0m \u001b[39mreturn\u001b[39;00m args, kwargs\n",
      "File \u001b[0;32m~/School/projectGNNs/GraphNeuralNetworks-ICAPS/.venv/lib/python3.9/site-packages/torch_geometric/nn/to_hetero_transformer.py:400\u001b[0m, in \u001b[0;36mToHeteroTransformer.map_args_kwargs.<locals>._recurse\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    396\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_by_name(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00mkey2str(key[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m),\n\u001b[1;32m    397\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_by_name(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00mkey2str(key[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m),\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    399\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _recurse(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m value\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)  # TODO\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)  # TODO\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    # def forward(self, x, edge_index):\n",
    "    #     x = F.dropout(x, p=0.5, training=self.training)\n",
    "    #     x = self.conv1(x, edge_index)\n",
    "    #     x = F.elu(x)\n",
    "    #     x = F.dropout(x, p=0.5, training=self.training)\n",
    "    #     x = self.conv2(x, edge_index)\n",
    "    #     return x\n",
    "\n",
    "\n",
    "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')\n",
    "print(model)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# def train():\n",
    "#       model.train()\n",
    "#       optimizer.zero_grad()  # Clear gradients.\n",
    "#       out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "#       loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "#       loss.backward()  # Derive gradients.\n",
    "#       optimizer.step()  # Update parameters based on gradients.\n",
    "#       return loss\n",
    "\n",
    "# def test(mask):\n",
    "#       model.eval()\n",
    "#       out = model(data.x, data.edge_index)\n",
    "#       pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "#       correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.\n",
    "#       acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
    "#       return acc\n",
    "\n",
    "\n",
    "# for epoch in range(1, 201):\n",
    "#     loss = train()\n",
    "#     val_acc = test(data.val_mask)\n",
    "#     test_acc = test(data.test_mask)\n",
    "#     print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1172e531ab8478d4e10fbb97f559e9ef9ccd07a6866ca5c6a8d4c17cc92a306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
