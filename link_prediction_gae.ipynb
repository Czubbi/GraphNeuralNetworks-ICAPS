{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing run.sh inside /Users/bartoszlachowicz/Desktop/Codeprojects/mac-bash-commands/goto/run.sh\n",
      "Executing run.sh inside /Users/bartoszlachowicz/Desktop/Codeprojects/mac-bash-commands/python-venv/run.sh\n"
     ]
    }
   ],
   "source": [
    "!source .venv/bin/activate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from copy import deepcopy\n",
    "\n",
    "#printing\n",
    "from torch_geometric import utils\n",
    "import networkx as nx\n",
    "\n",
    "# Torch\n",
    "from torch_geometric.nn import GCNConv, TransformerConv\n",
    "from torch.utils.data import random_split, SubsetRandomSampler, Subset\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Edges = Dict[Tuple[int, int], Tuple[int, ...]]\n",
    "Nodes = Dict[int, Tuple[int, ...]]\n",
    "all_edges: Dict[Tuple[int, int], Tuple[int, ...]] = {}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "def datasets(data_directory):\n",
    "    datasets = {}\n",
    "    for domain_name in os.listdir(data_directory):\n",
    "        domain_path = os.path.join(data_directory, domain_name)\n",
    "        data_loader = dataset_from_domain(domain_path)\n",
    "        datasets[domain_name] = data_loader\n",
    "    return datasets\n",
    "\n",
    "def dataset_from_domain(domain_path):\n",
    "    domain_name = os.path.basename(domain_path)\n",
    "    dataset = []\n",
    "    number_of_problems = 0\n",
    "    for problem_name in os.listdir(domain_path):\n",
    "        if problem_name == \"empty_causal_graphs\":\n",
    "            continue\n",
    "        number_of_problems+=1\n",
    "        problem_path = os.path.join(domain_path, problem_name)\n",
    "        data = problem_path_to_data(problem_path)\n",
    "        dataset.append(data)\n",
    "        # Generate list of data objects from our problem path\n",
    "        \n",
    "        # Iterate over all the problems in the domain\n",
    "        # Generate a data object for each problem\n",
    "        # train_test_split everything\n",
    "        # train the model\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_dataset(dataset, test_size=0.2, batch_size=8, shuffle=True, random_seed=42) -> Tuple[DataLoader, DataLoader]:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(0.2 * dataset_size))\n",
    "    if True :\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, test_indicies = indices[split:], indices[:split]\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "\n",
    "    for i in range(len(satellite_dataset)):\n",
    "        if i in train_indices:\n",
    "            train_set.append(satellite_dataset[i])\n",
    "        else:\n",
    "            test_set.append(satellite_dataset[i])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_loader, test_set\n",
    "\n",
    "    \n",
    "\n",
    "def problem_path_to_data(problem_path):\n",
    "    # print(problem_path)\n",
    "    cg_df = pd.read_csv(os.path.join(problem_path, 'cg.csv'), index_col=[0, 1])\n",
    "    cg_df.sort_index(inplace=True)\n",
    "    nodes_df = pd.read_csv(os.path.join(problem_path, 'nodes.csv'), index_col=0)\n",
    "\n",
    "    edges = cg_df.index\n",
    "    edge_features_list = cg_df[['type_pre_eff', 'type_eff_eff']].values\n",
    "    edge_labels = cg_df['label'].values\n",
    "    edge_dict = {}\n",
    "\n",
    "    # Unlucky naming, but the edge_features is a vector representing features of a single edge\n",
    "    # edge_feature_list is the dictionary of all the edges and their respective features\n",
    "    for edge, edge_features, label in zip(edges, edge_features_list, edge_labels):\n",
    "        edge_dict[tuple(edge)] = (edge_features, label)\n",
    "\n",
    "    edge_features, edge_labels = zip(*[edge_dict[edge] for edge in sorted(edge_dict.keys())])\n",
    "\n",
    "\n",
    "    data = Data(\n",
    "        x=torch.tensor(nodes_df.values, dtype=torch.float),\n",
    "        edge_index=torch.tensor(list(sorted(edge_dict.keys())), dtype=torch.long).t().contiguous(),\n",
    "        edge_attr=torch.tensor(edge_features, dtype=torch.float),\n",
    "        y=torch.tensor(edge_labels, dtype=torch.bool)\n",
    "    )\n",
    "    return data\n",
    "\n",
    "    \n",
    "def draw_graph(data: Data):\n",
    "    g = utils.to_networkx(data)\n",
    "\n",
    "    color = ['green' if data.y[i] else 'red' for i in range(data.y.size(0))]\n",
    "    a = nx.draw_networkx(g,node_size=200, pos=nx.spectral_layout(g), edge_color=color, node_color='green', with_labels=True)\n",
    "\n",
    "satellite_dataset = dataset_from_domain('graph_training_data/satellite')\n",
    "train_loader, test_set = split_dataset(satellite_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, features_num):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = TransformerConv(\n",
    "            in_channels=features_num,\n",
    "            out_channels=128,\n",
    "            edge_dim=2\n",
    "        )\n",
    "        self.conv2 = TransformerConv(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            edge_dim=2)\n",
    "\n",
    "    def encode(self, data: Data):\n",
    "        x = self.conv1(\n",
    "            x=data.x,\n",
    "            edge_index=data.edge_index,\n",
    "            edge_attr=data.edge_attr) # convolution 1\n",
    "        x = x.relu()\n",
    "        return self.conv2(\n",
    "            x=x, \n",
    "            edge_index=data.edge_index) # convolution 2\n",
    "\n",
    "\n",
    "\n",
    "    def decode(self, z, edge_index): # only pos and neg edges\n",
    "        #TODO  edge_index[0] 7 4 9\n",
    "        #TODO edge_index[1] 5 3 9\n",
    "        #     print(\"z shape: \", z.shape)\n",
    "\n",
    "        # Multiply adjecency matrix with latent space using the COO format of \n",
    "        # Edge index[0] and Edge index[1]\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z): \n",
    "        prob_adj = z @ z.t() # get adj NxN\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t() # get predicted edge_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 1])\n",
      "torch.Size([25, 1])\n"
     ]
    }
   ],
   "source": [
    "data_loader = train_loader\n",
    "test_loader = DataLoader(test_set, batch_size=8)\n",
    "\n",
    "num_node_features = next(iter(data_loader)).x.shape[1]\n",
    "model = Net(num_node_features)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "batch = next(iter(data_loader))\n",
    "print(batch[0].x.shape)\n",
    "print(batch[1].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DomainTrainer:\n",
    "#     def __init__(self, train_loader, test_set):\n",
    "#         self.train_loader = train_loader\n",
    "#         self.test_set = test_set\n",
    "\n",
    "#         data_loader = train_loader\n",
    "\n",
    "#         num_node_features = next(iter(data_loader)).x.shape[1]\n",
    "#         model = Net(num_node_features)\n",
    "#         optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "#         batch = next(iter(data_loader))\n",
    "#         print(batch[0].x.shape)\n",
    "#         print(batch[1].x.shape)\n",
    "\n",
    "def train():\n",
    "    model.train()  # Flag to modify the gradient\n",
    "\n",
    "    batch = next(iter(data_loader))  # This is next level shit\n",
    "    # print(batch[0])\n",
    "    # print(batch[1])\n",
    "    edge_index = batch.edge_index\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(batch) \n",
    "    link_logits = model.decode(z, edge_index) # decode\n",
    "    print(link_logits)\n",
    "    # print(link_logits)\n",
    "    link_labels = batch.y\n",
    "    # print(link_labels)\n",
    "    link_labels = link_labels.type(torch.float)\n",
    "    # print(link_labels)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_data = next(iter(test_loader))\n",
    "    z = model.encode(test_data) # encode train\n",
    "    link_logits = model.decode(z, test_data.edge_index) # decode test or val\n",
    "    link_probs = link_logits.sigmoid() # apply sigmoid\n",
    "    link_labels = test_data.y.type(torch.float)\n",
    "    \n",
    "    return roc_auc_score(link_labels, link_probs) #compute roc_auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJądro Kernel uległo awarii podczas wykonywania kodu w bieżącej komórce lub w poprzedniej komórce. Przejrzyj kod w komórkach, aby zidentyfikować możliwą przyczynę awarii. Kliknij <a href='https://aka.ms/vscodeJupyterKernelCrash'>tutaj</a>, aby uzyskać więcej informacji. W celu uzyskania dalszych szczegółów, wyświetl <a href='command:jupyter.viewOutput'>log</a> Jupyter."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 300):\n",
    "    train_loss = train()\n",
    "\n",
    "    test_perf = test()\n",
    "    # if val_perf > best_val_perf:\n",
    "    #     best_val_perf = val_perf\n",
    "    #     test_perf = tmp_test_perf\n",
    "    # log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Test: {:.4f}'\n",
    "    if epoch % 10 == 0:\n",
    "\n",
    "        print(log.format(epoch, train_loss, test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "£"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f3cd47e8294954fd18af9024571d3e60d92c8fd24f506352a1bb4b0f54cbdcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
